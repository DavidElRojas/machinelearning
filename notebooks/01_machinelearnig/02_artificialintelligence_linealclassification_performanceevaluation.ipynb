{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--NAVIGATION-->\n",
    "<a href=\"https://colab.research.google.com/github/marcoteran/machinelearning/blob/master/notebooks/01_machinelearning/02_artificialintelligence_linealclassification_performanceevaluation.ipynb\" target=\"_blank\"><img align=\"left\" src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Abrir en Colab\" title=\"Abrir y ejecutar en Google Colaboratory\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejemplo de código\n",
    "# Sesión 02: Clasificación Lineal y Evaluación del Desempeño\n",
    "## Inteligencia Artificial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Name:** Marco Teran **E-mail:** marco.tulio.teran@gmail.com,\n",
    "[Website](http://marcoteran.github.io/),\n",
    "[Github](https://github.com/marcoteran),\n",
    "[LinkedIn](https://www.linkedin.com/in/marcoteran/).\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definimos primero unas librerías y funciones que vamos a usar a durante la sesión:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pylab as pl\n",
    "import pandas as pd\n",
    "import seaborn as sns; sns.set()\n",
    "from sklearn import preprocessing\n",
    "from sklearn import datasets\n",
    "from sklearn.datasets.samples_generator import make_blobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_data(X, y):   #Función para graficar datos (X,y)\n",
    "    y_unique = np.unique(y)\n",
    "    colors = pl.cm.rainbow(np.linspace(0.0, 1.0, y_unique.size))\n",
    "    for this_y, color in zip(y_unique, colors):\n",
    "        this_X = X[y == this_y]\n",
    "        pl.scatter(this_X[:, 0], this_X[:, 1],  c=color.reshape(1,-1),\n",
    "                    alpha=0.5, edgecolor='k',\n",
    "                    label=\"Class %s\" % this_y)\n",
    "    pl.legend(loc=\"best\")\n",
    "    pl.title(\"Data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_decision_region(X, pred_fun):      #Función para visualizar la superficie de decisión de nuestro algoritmo.\n",
    "    min_x = np.min(X[:, 0])\n",
    "    max_x = np.max(X[:, 0])\n",
    "    min_y = np.min(X[:, 1])\n",
    "    max_y = np.max(X[:, 1])\n",
    "    min_x = min_x - (max_x - min_x) * 0.05\n",
    "    max_x = max_x + (max_x - min_x) * 0.05\n",
    "    min_y = min_y - (max_y - min_y) * 0.05\n",
    "    max_y = max_y + (max_y - min_y) * 0.05\n",
    "    x_vals = np.linspace(min_x, max_x, 100)\n",
    "    y_vals = np.linspace(min_y, max_y, 100)\n",
    "    XX, YY = np.meshgrid(x_vals, y_vals)\n",
    "    grid_r, grid_c = XX.shape\n",
    "    ZZ = np.zeros((grid_r, grid_c))\n",
    "    for i in range(grid_r):\n",
    "        for j in range(grid_c):\n",
    "            ZZ[i, j] = pred_fun(XX[i, j], YY[i, j])\n",
    "    pl.contourf(XX, YY, ZZ, 100, cmap = pl.cm.coolwarm, vmin= -1, vmax=2)\n",
    "    pl.colorbar()\n",
    "    pl.xlabel(\"x\")\n",
    "    pl.ylabel(\"y\")\n",
    "    \n",
    "def gen_pred_fun(clf):\n",
    "    def pred_fun(x1, x2):\n",
    "        x = np.array([[x1, x2]])\n",
    "        return clf.predict(x)[0]\n",
    "    return pred_fun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_cm(cm,classes):     #función para generar de una forma más visual la matriz de confusión\n",
    "    if len(cm)==2:\n",
    "      row_0 =['','Valor','Verdadero']\n",
    "      row_1 =['-',classes[0],classes[1]]\n",
    "      row_2 =[classes[0],cm[0,0],cm[1,0]]\n",
    "      row_3 =[classes[1],cm[0,1],cm[1,1]]\n",
    "      table = zip(row_0,row_1, row_2, row_3)\n",
    "      headers = ['', '', 'Valor', 'Predicho']  \n",
    "      return print(tabulate(table, headers=headers, floatfmt=\".4f\"))\n",
    "    else:\n",
    "      row_0 =['','Valor','Verdadero','']\n",
    "      row_1 =['-',classes[0],classes[1],classes[2]]\n",
    "      row_2 =[classes[0],cm[0,0],cm[1,0],cm[2,0]]\n",
    "      row_3 =[classes[1],cm[0,1],cm[1,1],cm[2,1]]\n",
    "      row_4 =[classes[2],cm[0,2],cm[1,2],cm[2,2]]\n",
    "      table = zip(row_0,row_1, row_2, row_3, row_4)\n",
    "      headers = ['', '', 'Valor', 'Predicho', '']  \n",
    "      return print(tabulate(table, headers=headers, floatfmt=\".4f\"))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regresión logística\n",
    "\n",
    "La regresión logística es un modelo lineal para clasificación. Es conocida también como regresión logit o clasificador de máxima entropía. Dado un vector de características $x$ para un ejemplo concreto, tenemos que:\n",
    "\n",
    "* Podemos establecer una función de predicción $f:\\mathbb{R}^{2}\\rightarrow\\mathbb{R}$ tal que:\n",
    "\n",
    "$$\\textrm{Prediction}(x)=\\begin{cases}\n",
    "C_{1} & \\mbox{si }f(x)\\ge \\theta\\\\\n",
    "C_{2} & \\mbox{si }f(x)<\\theta\n",
    "\\end{cases}$$\n",
    "\n",
    "* **A diferencia de la demo de la primera sesión**, aquí usaremos una función $f$ como un modelo logístico de los parámetros $w$ y $w_0$:\n",
    "\n",
    "$$f_w(x) = P(C_1|x)= \\sigma(wx+w_0)$$\n",
    "\n",
    "donde\n",
    "$$\\sigma(x) = \\frac{1}{1+e^{-x}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(-5, 5, 0.01)\n",
    "pl.plot(x, 1/(1+np.exp(-x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* La función logística se comporta de la siguiente manera:\n",
    "\n",
    "<img src=\"https://github.com/marcoteran/machinelearning/raw/master/notebooks/01_machinelearnig/figures/logistic2.svg\" width=\"80%\">\n",
    "\n",
    "El objetivo del modelo consiste en ajustar los coeficientes de $f$ con el objetivo de predecir de forma correcta la clase de cada ejemplo\n",
    "\n",
    "## Comparación contra una función de discriminación lineal\n",
    "\n",
    "A continuación, cargamos de nuevo el conjunto de datos usado en la demo de la sesión anterior y comparamos el desempeño de LogisticRegression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = make_blobs(n_samples=100, centers=2, n_features=2, random_state=0)\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Graficamos los datos generados artificialmente como sigue:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.figure(figsize=(8, 6))\n",
    "pl.xlabel('Feature 1')\n",
    "pl.ylabel('Feature 2')\n",
    "plot_data(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementación de LogisticRegression usando Scikit-Learn\n",
    "\n",
    "<img src=\"https://github.com/marcoteran/machinelearning/raw/master/notebooks/01_machinelearnig/figures/Scikit-learn.svg\" width=\"60%\">\n",
    "\n",
    "Todos los modelos de clasificación soportados por Scikit-Learn siguen el flujo de trabajo presentado en el gráfico anterior. Durante la sesión vamos a trabajar en la parte de entrenamiento y predicción. En la siguiente sesión se completará el flujo de trabajo revisando la parte de generalización. Scikit-Learn nos permite entrenar modelos de predicción automática a través de un API muy consistente. La implementación de regresión logística se encuentra usando `sklearn.linear_model.LogisticRegression`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primero declaramos un modelo de tipo `LogisticRegression`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = LogisticRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para entrenar el modelo a partir de nuestros datos, se hace un llamado a la función `fit()` usando los datos de entrenamiento. `fit()` recibe como parámetros la matriz de características (datos de entrada) y las etiquetas del conjunto de datos (datos de salida)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si se desean conocer los parámetros del estimador que se está entrenando, podemos llamar la función `classifier.get_params()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explicación de los parámetros:\n",
    "\n",
    "A continuación, presentamos una descripción de los ṕarámetros más importantes del modelo de regresión logística usando Scikit-Learn:\n",
    "\n",
    "* $C$: parámetro de regularización. Aunque el concepto de sobreajuste se verá en la siguiente sesión, $C$ penaliza los modelos que se ajusten demasiado al conjunto de datos.\n",
    "* $class\\_weight$: En caso de que el problema de clasificación sea desbalanceado, es decir, existen más elementos de una clase que de la otra, se puede dar mayor peso a aquellas muestras provenientes de la clase de menor número de ejemplos.\n",
    "* $n\\_jobs$: Número de procesos a usar para paralelizar el proceso de entrenamiento. -1 Usa todos los procesadores disponibles menos 1.\n",
    "* $solver$: `{‘newton-cg’, ‘lbfgs’, ‘liblinear’, ‘sag’, ‘saga’}`. Este parámetro corresponde al algoritmo usado para la optimización. La implementación de `liblinear` se encuentra escrita en C++ y es una de las más usadas. `sag` y `saga` recaen en una implementación de gradiente descendente conocida como `Stochastic Average Gradient`.\n",
    "\n",
    "Para consultar el significado de los otros parámetros y el modelo de regresión logística de skilearn puede consultar: https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para la fase de predicción, basta con llamar `predict()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para la fase de evaluación, basta con llamar la función `score()`, la cual calcula el porcentaje de errores cometidos en la predicción."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(classifier.predict(X) == y).sum()/y.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.score(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación, encontramos la superficie de decisión. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.figure(figsize = (8,16/3))    \n",
    "plot_decision_region(X, gen_pred_fun(classifier))\n",
    "plot_data(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aplicando regresión logística al conjunto de datos IRIS:\n",
    "\n",
    "## Carga de datos para Scikit-Learn\n",
    "\n",
    "Los datos en Scikit-Learn se asume que están almacenados en un arreglo de dos dimensiones, cuyo tamaño es [n_muestras, n_características]. Aunque muchos de los algoritmos de Scikit reciben [matrices sparse](http://www.scipy-lectures.org/advanced/scipy_sparse/index.html) de SciPy del mismo tamaño.\n",
    "\n",
    "- `n_muestras`: El número de muestras. Cada muestra es un item a procesar, en este caso a clasificar. Una muestra consiste en una imagen, un documento, un video, una fila en una base de datos.\n",
    "- `n_características`: El número de características o rasgos que son usados para describir cada item de forma cuantitativa. Estas características son por lo general valores continuos, aunque también pueden ser boleanos o valores discretos.\n",
    "\n",
    "El número de características es establecido de antemano, inclusive pueden ser de una alta dimensionalidad. En resumen, en el arreglo de dos dimensiones cada fila corresponderá a un ejemplo del conjunto de datos y cada columna corresponderá a una característica asociada.\n",
    "\n",
    "## Conjunto de datos IRIS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = datasets.load_iris()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos observar que contiene este objeto que nos regresa scikit-learn usando `keys()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `data`: Contiene la matriz de datos descrita en la sección anterior. \n",
    "* `target`: Las etiquetas de cada uno de las instancias del conjunto de datos (Filas de la matriz).\n",
    "* `target_names`: Son los nombres asociados a las etiquetas.\n",
    "* `feature_names`: Nombres de las características asociadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(iris['DESCR'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encontramos que el número de muestras y características de `data` es:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples, n_features = iris.data.shape\n",
    "print('Número de muestras:', n_samples)\n",
    "print('Número de características:', n_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observamos que cada fila corresponde a un ejemplar de una especie de flor. Cada flor tiene asociado una serie de características, como el ancho y largo del sépalo, y el ancho y largo del pétalo.\n",
    "\n",
    "<img src=\"https://github.com/marcoteran/machinelearning/raw/master/notebooks/01_machinelearnig/figures/iris_petal_sepal.png\" width=\"50%\">\n",
    "\n",
    "Podemos inspeccionar de forma manual las características del último elemento del conjunto de datos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list(zip(iris.feature_names, iris.data[-1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verificamos que `iris.target` sea del mismo tamaño que el número de muestras en `iris.data`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(iris.target.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las especies que tratamos de predecir son:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(iris.target_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La distribución de elementos por etiqueta está distribuída en el conjunto de datos, es decir, existe el mismo número de flores por especie:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list(zip(iris.target_names, np.bincount(iris.target))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualización usando Pandas\n",
    "\n",
    "La función `scatter_matrix` de Pandas nos permite visualizar cada elemento del conjunto de datos como una comparación entre características:\n",
    "* Largo del sépalo (cm)\n",
    "* Ancho del sépalo (cm)\n",
    "* Largo del pétalo (cm)\n",
    "* Ancho del pétalo (cm)\n",
    "\n",
    "A continuación comparamos cada pareja de características usando `scatter_matrix`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import cm\n",
    "cmap = cm.get_cmap('Set1') # Colour map (there are many others)\n",
    "\n",
    "iris_df = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
    "pd.plotting.scatter_matrix(iris_df, c=iris.target, cmap=cmap, figsize=(15, 15));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encontramos que la clase representada de color rojo, es la clase Iris Setosa."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clasificación binaria usando Scikit-Learn\n",
    "\n",
    "Ahora que conocemos el conjunto de datos IRIS, queremos entrenar un modelo que sea capaz de clasificar de forma automática cualquier flor representada en un conjunto de datos (Ancho del pétalo (cm), largo del sépalo (cm)', largo del pétalo (cm)', ancho del pétalo (cm)). Como en la demo anterior, filtramos aquellas flores que pertenezcan a la clase versicolor y virginica. Para verificar qué columnas corresponde al largo del sépalo y al ancho del pétalo, imprimimos `feature_names`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(iris.feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = iris.data[:,[0, 3]] # Columna 0: Largo del sépalo, Columna 3: Ancho del pétalo\n",
    "y = iris.target\n",
    "\n",
    "X = X[(y == 1) | (y == 2)] # Filtramos la clase 1 y 2 que corresponden a versicolor y virginica.\n",
    "y = y[(y == 1) | (y == 2)] \n",
    "\n",
    "y = y - 1 # Para que las clases queden entre 0 y 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrenamos el modelo `LogisticRegression` y verificamos los valores predichos. `LogisticRegression` es un modelo lineal, lo que significa que creará una decisión que es lineal en el espacio de entrada. Es decir, encuentra una linea que separa los datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = LogisticRegression()\n",
    "classifier.fit(X, y)\n",
    "predictions = classifier.predict(X)\n",
    "\n",
    "print('Número de instancias a predecir: {}'.format(y.shape[0]))\n",
    "print('Valores de verdad: {}'.format(y))\n",
    "print('Valores predichos: {}'.format(predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pregunta**\n",
    "* ¿Cómo evaluamos el desempeño de nuestro clasificador?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluación del desempeño - Clasificación binaria"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con el objetivo de conocer el desempeño de nuestro clasificador, se mide cuantitativamente cuantas predicciones fueron correctas. Este número se conoce como **exactitud** o **accuracy** en inglés."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = classifier.predict(X)\n",
    "np.mean(prediction == y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scikit nos permite evaluar también el accuracy con la función `.score()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.score(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matriz de confusión\n",
    "\n",
    "Sin embargo, es deseable conocer qué clases clasifica mejor. Para poder visualizar esta información, usaremos la matriz de confusión, la cual es una clase especial de tabla de contingencia en la cual se comparan las clases reales contra las clases predichas por el clasificador. Scikit-Learn nos permite construír la matriz de confusión usando `sklearn.metrics.confusion_matrix`. `confusion_matrix` recibe como argumento dos listas o arreglos de NumPy:\n",
    "* $y$: Etiquetas reales del conjunto de datos\n",
    "* $\\hat{y}$: Etiquetas predichas por el clasificador sobre el conjunto de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "prediction = classifier.predict(X)\n",
    "cnf_matrix = confusion_matrix(y, prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`confusion_matrix` regresa una matriz de tamaño [$\\textit{n_clases}$, $\\textit{n_clases}$], dónde $\\textit{n_clases}$ corresponde al número de clases únicas en el conjunto de datos. La matriz de confusión nos permite comparar el rendimiento de nuestro clasificador clase por clase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cnf_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación, vamos a definir una función para generar de una forma más visual la matriz de confusión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          title='Matriz de confusión',\n",
    "                          cmap=pl.cm.Blues):\n",
    "    print(cm) # Confusion matrix\n",
    "\n",
    "    pl.imshow(cm, interpolation='nearest', cmap=cmap) # Pintamos la matriz como una imagen\n",
    "    pl.title(title)\n",
    "    pl.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    pl.xticks(tick_marks, classes, rotation=45) # Nombre de las clases en X\n",
    "    pl.yticks(tick_marks, classes) # Nombre de las clases en Y\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        pl.text(j, i, format(cm[i, j], 'd'),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\") \n",
    "        # Anotamos cada sección de la imagen con su valor correspondiente en la matriz\n",
    "\n",
    "    pl.tight_layout()\n",
    "    pl.ylabel('Valor de verdad')\n",
    "    pl.xlabel('Valor predicho')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De nuevo, generamos la matriz de confusión y se la pasamos como parámetro a la función recién creada `plot_confusion_matrix`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = iris.target_names[1:] # Recordemos que estamos comparando la clase 1 y 2\n",
    "\n",
    "cnf_matrix = confusion_matrix(y, prediction)\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "pl.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=class_names,\n",
    "                      title='Matriz de confusión')\n",
    "\n",
    "pl.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **¿Cómo interpretarla?**\n",
    "\n",
    "* Los valores en la diagonal indican los aciertos de nuestro clasificador. Por ejemplo, sabemos que de 50 ejemplos de la clase versicolor, supo clasificar 46. Mientras que de 50 ejemplos de la clase virginica, se equivocó en 6.\n",
    "* El accuracy y el error pueden ser a su vez definidos desde la matriz de confusión:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = np.sum([cnf_matrix[i, i] for i in range(cnf_matrix.shape[0])])/np.sum(cnf_matrix)\n",
    "\n",
    "print('Accuracy: {}'.format(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "err = np.sum([cnf_matrix[0, 1], cnf_matrix[1, 0]])/np.sum(cnf_matrix)\n",
    "\n",
    "print('Error: {}'.format(err))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ¿Qué pasa cuando el problema es imbalanceado?\n",
    "\n",
    "Supongamos un clasificador $G$ con el siguiente desempeño sobre un conjunto de datos:\n",
    "\n",
    "* $Accuracy = \\frac{99}{100} = 99\\%$  \n",
    "* $Error = \\frac{1}{100} = 1\\%$  \n",
    "\n",
    "**¿Es un buen clasificador?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para medir efectivamente si $G$ es un buen clasificador, presentamos la matriz de confusión producto de sus predicciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['$C_+$', '$C_-$']\n",
    "\n",
    "y_pred = np.ones(100)\n",
    "y_test = np.ones(100)\n",
    "y_test[-1] = 0\n",
    "mat = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "pl.figure()\n",
    "plot_confusion_matrix(mat, classes=class_names,\n",
    "                      title='Matriz de confusión sobre $G$');\n",
    "\n",
    "pl.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A pesar de que el modelo clasificó correctamente 99 muestras de la clase negativa, falló en clasificar la única muestra positiva del conjunto de datos.\n",
    "\n",
    "### Precisión, Recall y F1 \n",
    "La matriz de confusión nos permite calcular otra serie de medidas para evaluar el desempeño del clasificador. Para introducir estas medidas, vamos a descomponer la matriz de confusión en cuatro partes:\n",
    "\n",
    "<img src=\"figures/confusion_matrix_1.png\" width=\"30%\">\n",
    "\n",
    "Los componentes de esta matriz pueden interpretarse como:\n",
    "* TP: Verdaderos positivos. Resultado correcto para la clase positiva.\n",
    "* TN: Verdaderos negativos. Ausencia correcta para la clase positiva.\n",
    "* FP: Falsos positivos. Resultados inesperados.\n",
    "* FN: Falsos negativos. Resultados faltantes.\n",
    "\n",
    "Vale la pena aclarar que en clasificación binaria, los terminos *positivo* o *negativo* se refieren a la predicción del clasificador (Clase), mientras que *verdadero* o *falso* se refieren a si la predicción fue correcta o no."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De esta matriz podemos volver a escribir las definiciones de accuracy y error:\n",
    "* $accuracy = \\frac{TP + TN}{TP + FN + FP + TN}$\n",
    "* $error = \\frac{FP + FN}{TP + FN + FP + TN}$  \n",
    "\n",
    "Así como las definiciones de precisión, recall y f1 score:\n",
    "\n",
    "* $PRE = \\frac{TP}{TP + FP}$ \n",
    "* $REC = \\frac{TP}{FN + TP}$ \n",
    "* $F_1 = 2 * \\frac{PRE*REC}{PRE + REC}$\n",
    "\n",
    "La precisión se puede definir como la habilidad del clasificador de **no** clasificar una muestra como positiva cuando es negativa. Mientras el recall (índice de recuperación) se puede definir como la capacidad del clasificador de encontrar todas las muestras positivas. $F_1 \\textit{score}$ se define como el promedio pesado de precisión y recall. Evaluemos la precision y el índice de recuperación de nuestro clasificador $G$:\n",
    "\n",
    "* $PRE = \\frac{0}{0}$ = No definida\n",
    "* $REC = \\frac{0}{1} = 0\\%$ Recall\n",
    "\n",
    "Scikit-learn provee diferentes funciones para calcular estas tres medidas. Vamos a medir el desempeño sobre el clasificador $G$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "print('Precision: {}'.format(metrics.precision_score(y_test, y_pred, pos_label=0)))\n",
    "print('Recall: {}'.format(metrics.recall_score(y_test, y_pred, pos_label=0)))\n",
    "print('F_1 score: {}'.format(metrics.f1_score(y_test, y_pred, pos_label=0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El parámetro `pos_label` indica cual etiqueta corresponde a la clase positiva. Para nuestro ejemplo hemos tomado la clase $0$ como la clase positiva. Por otro lado, el `Warning` generado por Scikit-Learn corresponde a que la medida no se pudo calcular de forma correcta, por la presencia de un denominador en $0$, por lo tanto se le asigna $0$ a la medida. Estas medidas nos indican que el clasificador $G$ no es la mejor opción para resolver el problema. \n",
    "\n",
    "### Precisión, recall y F1 sobre IRIS\n",
    "Regresando al problema de clasificación binario sobre IRIS, podemos calcular precision, recall y F1 de la misma manera:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Precision: {}'.format(metrics.precision_score(y, prediction)))\n",
    "print('Recall: {}'.format(metrics.recall_score(y, prediction)))\n",
    "print('F_1 score: {}'.format(metrics.f1_score(y, prediction)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clasificación multiclase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**¿Cómo extender a una solución que involucre más de dos clases?**\n",
    "\n",
    "Existen dos soluciones:\n",
    "* Uno contra el resto (One vs All). Para esto, seguimos los siguientes pasos:\n",
    "    * Construímos un clasificador usando regresión logística $h_\\theta^{(i)} (x)$ para cada clase $i$, en el cual se trata de predecir la probabilidad de que $y=i$\n",
    "    * Cuando llegue un nuevo ejemplo $x$, escogemos lo clase $i$ que maximize: \n",
    "$$\\max_{i} h_\\theta^{(i)} (x)$$\n",
    "\n",
    "<img src=\"figures/ovr_lr.png\" width=\"60%\">\n",
    "\n",
    "Fuente: https://www.coursera.org/learn/machine-learning/lecture/68Pol/multiclass-classification-one-vs-all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para indicar que la estrategia de clasificación multiclase es \"*One vs Rest*\", modificamos el parámetro `multi_class` en el llamado a `LogisticRegression()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = iris.data[:,[0, 2]] \n",
    "y = iris.target\n",
    "\n",
    "classifier_ovr = LogisticRegression(multi_class='ovr')\n",
    "classifier_ovr.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación visualizamos la función de decisión para el problema multiclase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.figure(figsize = (8,16/3))    \n",
    "plot_decision_region(X, gen_pred_fun(classifier_ovr))\n",
    "plot_data(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Regresión logística multinomial:\n",
    "    La función logística se puede generalizar para que aprenda una distribución de probabilidad sobre todas las clases. Esta función se conoce como función **SoftMax**. Para esto, $P(y=i\\mid \\mathbf {x} )$ se puede escribir así:\n",
    "$$P(y=i\\mid \\mathbf {x} )={\\frac {e^{\\mathbf {x} ^{\\mathsf {T}}\\mathbf {w} _{i}}}{\\sum _{k=1}^{K}e^{\\mathbf {x} ^{\\mathsf {T}}\\mathbf {w} _{k}}}}$$\n",
    "dónde $x$ corresponde a mi vector de características, $K$ al número de clases y $w$ a los coeficientes de la función $wx + w_0$ para la clase $i$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_multi = LogisticRegression(multi_class='multinomial', solver='lbfgs');\n",
    "classifier_multi.fit(X, y)\n",
    "\n",
    "pl.figure(figsize = (8,16/3))    \n",
    "plot_decision_region(X, gen_pred_fun(classifier_multi))\n",
    "plot_data(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluación del desempeño - Caso multiclase\n",
    "\n",
    "La matriz de confusión se puede extender al problema multiclase de la siguiente manera:\n",
    "\n",
    "### Matriz de confusión en el caso multiclase\n",
    "\n",
    "Primero, visualizaremos la matriz de confusión para el modelo de regresión logística multinomial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "class_names = iris.target_names\n",
    "\n",
    "y_pred = classifier_multi.predict(X)\n",
    "mat = confusion_matrix(y, y_pred)\n",
    "\n",
    "pl.figure()\n",
    "plot_confusion_matrix(mat, classes=class_names,\n",
    "                      title='Matriz de confusión - Multinomial LR');\n",
    "\n",
    "pl.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora calculamos la matriz de confusión para el método de regresión logística usando la estrategia \"*Uno contra todos*\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = classifier_ovr.predict(X)\n",
    "mat = confusion_matrix(y, y_pred)\n",
    "\n",
    "pl.figure()\n",
    "plot_confusion_matrix(mat, classes=class_names,\n",
    "                      title='Matriz de confusión - One vs All LR');\n",
    "\n",
    "pl.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A simple vista podemos mencionar que:\n",
    "* La clase *setosa* es fácil de clasificar para ambos clasificadores.\n",
    "* Aunque el modelo usando \"*Uno contra Todos*\" tiene mejor desempeño en la clase *virginica*, tiene un pésimo desempeño en la clase *versicolor*, con respecto al modelo usando regresión logística multinomial.\n",
    "\n",
    "De nuevo, es útil usar una medida de desempeño para comparar cuantitativamente el rendimiento de ambos modelos.\n",
    "\n",
    "### Accuracy multiclase\n",
    "\n",
    "El accuracy multiclase se define como la fracción de predicciones correctas del clasificador. Se puede calcular de la siguiente formula:\n",
    "\n",
    "$$\n",
    "\\texttt{acc}(y, \\hat{y}) = \\frac{1}{n} \\sum_{i=0}^{n-1} 1(\\hat{y}_i = y_i)\n",
    "$$\n",
    "\n",
    "dónde $y$ corresponde a la lista de etiquetas de verdad de nuestro conjunto de datos, mientras $\\hat{y}$ corresponde a los valores predichos por nuestro clasificador para el mismo conjunto de datos y **en el mismo orden**. $n$ corresponde al número de ejemplo del conjunto. Scikit-Learn nos permite calcular el accuracy de la misma manera:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy OVR classifier: {}'.format(classifier_ovr.score(X, y)))\n",
    "print('Accuracy Multinomial classifier: {}'.format(classifier_multi.score(X, y)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El modelo de regresión logística se desempeña mejor frente al modelo \"*Uno vs Todos*\". El error se puede definir como la fracción de predicciones incorrectas del clasificador:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Error OVR classifier: {}'.format(1-classifier_ovr.score(X, y)))\n",
    "print('Error Multinomial classifier: {}'.format(1-classifier_multi.score(X, y)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precision y recall en el problema multiclase\n",
    "\n",
    "Precision era calculado con base a la matriz de confusión del problema de clasificación binaria. Sin embargo, se puede extender como medida de desempeño para el problema multiclase de varias formas. Recordemos que:\n",
    "\n",
    "* $Precision = \\frac{TP}{TP + FP}$ \n",
    "* $Recall = \\frac{TP}{TP + FN}$ \n",
    "* $F_1 = 2 * \\frac{PRE*REC}{PRE + REC}$\n",
    "\n",
    "Para ilustrar como se calcula cada una de estas medidas, usaremos el clasificador de regresión logística con esquema \"*One vs All*\". Primero calculamos la *precision* para cada clase y luego determinamos la forma en la que combinamos las precisiones de cada clase:\n",
    "\n",
    "| Clase    | tp   | fp   | fn   | PRE  | REC  |\n",
    "|----------|------|------|------|------|------|\n",
    "|Setosa    | 50   | 0    | 0    | 1.0  | 1.0  |\n",
    "|          |      |      |      |      |      |\n",
    "|Versicolor| 40   | 1    | 10   | 0.98 | 0.8  |\n",
    "|          |      |      |      |      |      |\n",
    "|Virginica | 49   | 10   | 1    | 0.83 | 0.98 |\n",
    "\n",
    "Scikit-Learn nos permite calcular la precisión por clase así:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score\n",
    "y_pred = classifier_ovr.predict(X)\n",
    "print('Orden de las etiquetas: {}'.format(iris.target_names))\n",
    "print('Precision por clase: {}'.format(precision_score(y, y_pred, average=None)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Añadimos un par de cálculos a nuestra tabla, donde reflejamos la suma de los valores totales de verdaderos positivos, falsos positivos y falsos negativos. Existen varias formas de combinar las medidas de precisión y recall por clase:\n",
    "* `micro` : Cuenta el total de positivos verdaderos, falsos positivos y falsos negativos\n",
    "* `macro` : Calcula la precisión por clase y luego la promedia. (Sin tener en cuenta el balance de clases)\n",
    "* `weighted` : Calcula la precisión por clase y luego la promedia teniendo en cuenta el balance de clases\n",
    "\n",
    "| Clase    | tp   | fp   | fn   | PRE  | REC  |\n",
    "|----------|------|------|------|------|------|\n",
    "|Setosa    | 50   | 0    | 0    | 1.0  | 1.0  |\n",
    "|          |      |      |      |      |      |\n",
    "|Versicolor| 40   | 1    | 10   | 0.98 | 0.8  |\n",
    "|          |      |      |      |      |      |\n",
    "|Virginica | 49   | 10   | 1    | 0.83 | 0.98 |\n",
    "|          |      |      |      |      |      |\n",
    "|Sum(micro)| 139  | 11   | 11   | 0.92 | 0.92 |\n",
    "|          |      |      |      |      |      |\n",
    "|Avg(macro)|      |      |      | 0.93 | 0.92 |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Precisión macro: {}'.format(precision_score(y, y_pred, average='macro')))\n",
    "print('Precisión micro: {}'.format(precision_score(y, y_pred, average='micro')))\n",
    "print('Precisión pesada: {}'.format(precision_score(y, y_pred, average='weighted')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como observamos, estos valores corresponden a las dos últimas filas que se calcularon sobre la tabla de precisión y recall. Vale la pena anotar que `weighted` y `macro` son iguales por el balance de clases. Esto se puede extender al calculo del recall y el $F_1 \\textit{score}$. Recordemos que el $F_1 \\textit{score}$  es un promedio pesado de la precisión y el recall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import recall_score, f1_score\n",
    "\n",
    "print('Recall macro: {}'.format(recall_score(y, y_pred, average='macro')))\n",
    "print('Recall micro: {}'.format(recall_score(y, y_pred, average='micro')))\n",
    "print('Recall pesada: {}'.format(recall_score(y, y_pred, average='weighted')))\n",
    "\n",
    "print('F1 macro: {}'.format(f1_score(y, y_pred, average='macro')))\n",
    "print('F1 micro: {}'.format(f1_score(y, y_pred, average='micro')))\n",
    "print('F1 pesada: {}'.format(f1_score(y, y_pred, average='weighted')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Taller"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usando el conjunto de datos wine:\n",
    "\n",
    "Lo puede descargar [aquí](https://drive.google.com/open?id=0B8POkZpAJ5qQRlFzVUZnMlZVakk).\n",
    "Puede obtener más información del conjunto [aquí](https://archive.ics.uci.edu/ml/datasets/wine).\n",
    "\n",
    "El conjunto de datos contiene los ejemplos de 178 vinos. Cada uno identificado por 13 propiedades químicas:\n",
    "* Alcohol\n",
    "* Malic_acid\n",
    "* Ash\n",
    "* Alcalinity\n",
    "* Magnesium\n",
    "* Phenols\n",
    "* Flavanoids\n",
    "* Nonflavanoid\n",
    "* Proanthocyanins\n",
    "* Color\n",
    "* Hue\n",
    "* OD280/OD315\n",
    "* Proline\n",
    "\n",
    "A cada vino le fue asignada una clase, que corresponde al tipo de vino $[1, 2, 3]$\n",
    "\n",
    "Resuelva:\n",
    "* Cargue el conjunto de datos como un DataFrame de Pandas\n",
    "* Cargue la clase en un arreglo aparte. Eliminela del DataFrame de Pandas\n",
    "* Genere un histograma para cada propiedad del conjunto de datos\n",
    "* Use `scatter_matrix` y visualize todas las posibles combinaciones de características\n",
    "    * ¿Encuentra algún par de características en el que se observan las clases bien separadas?\n",
    "* Clasificación usando solo dos características y el esquema Multinomial:\n",
    "    * Entrene un modelo LogisticRegression para categorizar el tipo de vino usando `Proline` contra `Flavonoids`.\n",
    "    * Entrene otro modelo LogisticRegression para categorizar el tipo de vino usando `Alcalinity` contra `Malic Acid`.\n",
    "    * Imprima la región de decisión de cada clasificador.\n",
    "    * Genere la matriz de confusión de cada clasificador.\n",
    "    * Reporte el accuracy, el error de clasificación, la precisión macro, el recall macro y el F1 score macro.\n",
    "    * ¿Cual modelo se desempeña mejor? ¿Por qué?\n",
    "* Clasificación usando todas las características:\n",
    "    * Entrene un modelo LogisticRegression usando el esquema \"*One vs All*\".\n",
    "    * Entrene un modelo LogisticRegression usando el esquema multinomial.\n",
    "    * Genere la matriz de confusión de cada clasificador.\n",
    "    * Reporte el accuracy, el error de clasificación, la precisión por clase, el recall por clase y el F1 score por clase.\n",
    "    * ¿Cual modelo se desempeña mejor? ¿Por qué? ¿Cual clase es más sencilla para el clasificador?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
