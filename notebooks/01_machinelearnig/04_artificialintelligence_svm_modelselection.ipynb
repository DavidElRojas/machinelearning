{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--NAVIGATION-->\n",
    "<a href=\"https://colab.research.google.com/github/marcoteran/machinelearning/blob/master/notebooks/01_machinelearning/s4_artificialintelligence_svm_modelselection.ipynb\" target=\"_blank\"><img align=\"left\" src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Abrir en Colab\" title=\"Abrir y ejecutar en Google Colaboratory\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejemplo de código\n",
    "# Sesión 04: Máquinas de vectores de soporte y selección de modelos\n",
    "## Inteligencia Artificial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Name:** Marco Teran **E-mail:** marco.tulio.teran@gmail.com,\n",
    "[Website](http://marcoteran.github.io/),\n",
    "[Github](https://github.com/marcoteran),\n",
    "[LinkedIn](https://www.linkedin.com/in/marcoteran/).\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definimos primero unas librerías y funciones que vamos a usar a durante la sesión:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pylab as pl\n",
    "from sklearn.model_selection import train_test_split\n",
    "from matplotlib.colors import Normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para visualizar un conjunto de datos en 2D\n",
    "def plot_data(X, y):\n",
    "    y_unique = np.unique(y)\n",
    "    colors = pl.cm.rainbow(np.linspace(0.0, 1.0, y_unique.size))\n",
    "    for this_y, color in zip(y_unique, colors):\n",
    "        this_X = X[y == this_y]\n",
    "        pl.scatter(this_X[:, 0], this_X[:, 1],  c=color.reshape(1,-1),\n",
    "                    alpha=0.5, edgecolor='k',\n",
    "                    label=\"Class %s\" % this_y)\n",
    "    pl.legend(loc=\"best\")\n",
    "    pl.title(\"Data\")\n",
    "    \n",
    "# Función para visualizar de la superficie de decisión de un clasificador\n",
    "def plot_decision_region(X, pred_fun):\n",
    "    min_x = np.min(X[:, 0])\n",
    "    max_x = np.max(X[:, 0])\n",
    "    min_y = np.min(X[:, 1])\n",
    "    max_y = np.max(X[:, 1])\n",
    "    min_x = min_x - (max_x - min_x) * 0.05\n",
    "    max_x = max_x + (max_x - min_x) * 0.05\n",
    "    min_y = min_y - (max_y - min_y) * 0.05\n",
    "    max_y = max_y + (max_y - min_y) * 0.05\n",
    "    x_vals = np.linspace(min_x, max_x, 100)\n",
    "    y_vals = np.linspace(min_y, max_y, 100)\n",
    "    XX, YY = np.meshgrid(x_vals, y_vals)\n",
    "    grid_r, grid_c = XX.shape\n",
    "    ZZ = np.zeros((grid_r, grid_c))\n",
    "    for i in range(grid_r):\n",
    "        for j in range(grid_c):\n",
    "            ZZ[i, j] = pred_fun(XX[i, j], YY[i, j])\n",
    "    pl.contourf(XX, YY, ZZ, 100, cmap = pl.cm.coolwarm, vmin= -1, vmax=2)\n",
    "    pl.colorbar()\n",
    "    pl.xlabel(\"x\")\n",
    "    pl.ylabel(\"y\")\n",
    "    \n",
    "class MidpointNormalize(Normalize):\n",
    "    def __init__(self, vmin=None, vmax=None, midpoint=None, clip=False):\n",
    "        self.midpoint = midpoint\n",
    "        Normalize.__init__(self, vmin, vmax, clip)\n",
    "\n",
    "    def __call__(self, value, clip=None):\n",
    "        x, y = [self.vmin, self.midpoint, self.vmax], [0, 0.5, 1]\n",
    "        return np.ma.masked_array(np.interp(value, x, y))\n",
    "    \n",
    "def gen_pred_fun(clf):\n",
    "    def pred_fun(x1, x2):\n",
    "        x = np.array([[x1, x2]])\n",
    "        return clf.predict(x)[0]\n",
    "    return pred_fun\n",
    "\n",
    "def plot_labels(n_folds, n_classes, list_labels):\n",
    "    ind = np.arange(n_folds)\n",
    "    width = 0.15\n",
    "    \n",
    "    countings = []\n",
    "    for labels in list_labels:\n",
    "        labels = np.array(labels)\n",
    "        countings.append([np.count_nonzero(labels == x) for x in range(n_classes)])\n",
    "    \n",
    "    class_bars = []\n",
    "    for cls in range(n_classes):\n",
    "        class_bars.append([l[cls] for l in countings])\n",
    "    \n",
    "    fig, ax = pl.subplots()\n",
    "    i = 0\n",
    "    for class_bar in class_bars:\n",
    "        ax.bar(ind + width*i, class_bar, width, label='Clase '+str(i))\n",
    "        i += 1\n",
    "        \n",
    "    ax.set_xticks(ind + 2*width / 3)\n",
    "    ax.set_xticklabels(['Pliegue {}'.format(k) for k in range(n_folds)])\n",
    "    pl.legend(loc=\"best\")\n",
    "    pl.title(\"Etiquetas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Máquinas de vectores de soporte\n",
    "**Support Vector Machines**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las máquinas de vectores de soporte (SVM)  son un conjunto de modelos de aprendizaje supervisado que se utilizan para la clasificación, la regresión y la detección de valores atípicos, en el cual los ejemplos son representados en un nuevo espacio, de tal forma que aquellos ejemplos de diferentes categorías sea posible, en principio, separarlos linealmente.\n",
    "\n",
    "Las ventajas de las máquinas de vectores soporte son:\n",
    "* Son eficaces en espacios de alta dimensión.\n",
    "* Siguen siendo eficaces en los casos en que el número de dimensiones es mayor que el número de muestras.\n",
    "* Utiliza un subconjunto de puntos de entrenamiento en la función de decisión (llamados vectores de soporte), por lo que también es eficiente en cuanto a memoria.\n",
    "* **Versátil:** se pueden especificar diferentes funciones del Kernel para la función de decisión. Se proporcionan kernels comunes, pero también es posible especificar kernels personalizados.\n",
    "\n",
    "Las desventajas de las máquinas de vectores de soporte son:\n",
    "* Si el número de características es mucho mayor que el número de muestras, es crucial evitar el sobreajuste en la elección de las funciones Kernel y el término de regularización.\n",
    "* Las SVM no proporcionan directamente estimaciones de probabilidad, éstas se calculan mediante una costosa validación cruzada de cinco pliegues."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definición del conjunto de datos\n",
    "\n",
    "Vamos a trabajar con un conjunto de datos artificial (conjunto de datos de juguete). El conjunto es creado usando la funcionalidad `make_circles` de Scikit-Learn [ver más](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_circles.html).\n",
    "\n",
    "`make_circles` permite crear un círculo grande que contenga un círculo más pequeño en 2d.\n",
    "Un simple conjunto de datos de juguete para visualizar los algoritmos de agrupación y xclasificación.\n",
    "\n",
    "Considere el siguiente ejemplo de un conjunto de datos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargue las funciones datos make_circles n_samples=1000, factor=.3 (separación entre circulos), noise=.05\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se trata de un conjunto de datos que no es linealmente separable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dibuje los datos\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ¿Cómo separar los datos?\n",
    "\n",
    "SVM  crea, implícitamente, un espacio de representación de mayor dimensionalidad en el cual podemos separar de forma clara nuestros datos. Por ejemplo:\n",
    "\n",
    "<img src=\"https://github.com/marcoteran/machinelearning/raw/master/notebooks/01_machinelearnig/figures/kernel_trick.png\" width=\"60%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kernel trick\n",
    "\n",
    "SVM usa una función conocida como kernel. Intuitivamente, esta función $k$ define qué tan parecidas son dos instancias del conjunto de datos. Formalmente, la función $k$ calcula el producto punto en el espacio de caracterísiticas donde se representarán los datos. Dependiendo del kernel, este espacio de característica es de mayor dimensionalidad, y facilita la  definición de un \"*hiperplano*\" que separe los ejemplos de ambas características. \n",
    "\n",
    "Existen varias opciones para las funciones de kernel. Primero vamos a cargar dos conjuntos de datos sobre los cuales vamos a comparar la superficie de decisión generada por cada tipo de kernel.\n",
    "\n",
    "<img src=\"https://github.com/marcoteran/machinelearning/raw/master/notebooks/01_machinelearnig/figures/differentkernels.png\" width=\"60%\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar el conjunto de datos de iris (clases: versicolor y virginica)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividir el conjunto en 70% para entrenamiento y 30% para prueba\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar el conjunto de datos de iris: 600 muestras y noise 0.3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividir el conjunto en 70% para entrenamiento y 30% para prueba\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dibujar iris\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dibujar moon\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kernel Lineal\n",
    "\n",
    "La función $k$ está definida como:\n",
    "$$\n",
    "k(x,y) = \\langle x, x\\rangle = xx'\n",
    "$$\n",
    "\n",
    "Esta implementación puede ser consultada a través de `sklearn.svm.LinearSVC` [(ver más)](https://scikit-learn.org/stable/modules/generated/sklearn.svm.LinearSVC.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importamos el metodo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear dos clasificadores de kernel lineal: linear_iris y linear_moons\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenamos los modelo `LinearSVC` llamando la función `fit()` sobre el conjunto de datos reducido\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora visualizamos los datos de ambos y la superficie de decisión:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El error en el conjunto de entrenamiento y prueba es el siguiente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Error en entrenamiento para iris\n",
    "# Error en prueba para iris\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora hacemos los mismo para el conjunto de datos generado artificialmente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Error en entrenamiento para moons\n",
    "# Error en prueba para moons\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kernel polinomial\n",
    "\n",
    "La función $k$ está definida como:\n",
    "$$\n",
    "k(x,y) = (\\gamma \\langle x, x'\\rangle + r)^d\n",
    "$$\n",
    "dónde $d$ corresponde al grado del polinomio (parametro `degree`) y $r$ por `coef0`. De manera similar podemos acceder a la implementación de este kernel a través de `sklearn.svm.SVC` [(ver más)](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html).\n",
    "\n",
    "Definimos primero un kernel polinomial de grado $2$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importamos el metodo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definimos el clasificador con kernel='poly' y degree=2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenamos los modelo `SVC` llamando la función `fit()` sobre el conjunto de datos reducido\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora visualizamos los datos de ambos y la superficie de decisión:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora lo intentamos con un polinomio de grado $3$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Medimos el error en entrenamiento y prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Error en entrenamiento: {}\".format(1-poly_svm.score(X_train_moons, y_train_moons)))\n",
    "print(\"Error en prueba: {}\".format(1-poly_svm.score(X_test_moons, y_test_moons)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora probamos con el conjunto de datos IRIS $(d=4)$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly_svm = SVC(kernel='poly', degree=4)\n",
    "poly_svm.fit(X_train_iris, y_train_iris)\n",
    "\n",
    "pl.figure(figsize = (10, 6))    \n",
    "plot_decision_region(X_test_iris, gen_pred_fun(poly_svm))\n",
    "plot_data(X_test_iris, y_test_iris)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Error en entrenamiento\n",
    "# Error en prueba\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kernel Gaussiano\n",
    "\n",
    "\n",
    "$$\n",
    "K(x, x') = \\exp\\left(-\\frac{\\|x-x'\\|^2}{2\\sigma^2}\\right)\n",
    "$$\n",
    "la cual se puede simplificar como\n",
    "$$\n",
    "K(x, x') = \\exp(-\\gamma \\|x-x'\\|^2)\n",
    "$$\n",
    "\n",
    "donde $\\gamma$ se especifica mediante el parámetro `gamma`, que debe ser mayor que $0$.\n",
    "\n",
    "En la literatura este método tambien se encuentra como kernel usando una función de base radial (**RBF** por sus siglas en ingles)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al entrenar una SVM con el kernel de la función de base radial (RBF), hay que tener en cuenta dos parámetros: $C$ y $\\gamma$.\n",
    "* El parámetro $C$, común a todos los kernels de SVM, es el **parametro de regularización**, que compensa la clasificación errónea de las muestras de entrenamiento en la complejidad de la superficie de decisión.\n",
    "    - Un $C$ bajo hace que la superficie de decisión sea suave, mientras que un $C$ alto tiene como objetivo clasificar correctamente todos los ejemplos de entrenamiento.\n",
    "\n",
    "<img src=\"https://github.com/marcoteran/machinelearning/raw/master/notebooks/01_machinelearnig/figures/lowc.png\" width=\"40%\">\n",
    "<img src=\"https://github.com/marcoteran/machinelearning/raw/master/notebooks/01_machinelearnig/figures/highc.png\" width=\"40%\">\n",
    "\n",
    "* $\\gamma$ define cuánta influencia tiene una sola muestra de entrenamiento.\n",
    "    - Cuanto mayor sea $\\gamma$, más cerca deben estar las demás muestras para verse afectadas.\n",
    "\n",
    "<img src=\"https://github.com/marcoteran/machinelearning/raw/master/notebooks/01_machinelearnig/figures/highgamma.png\" width=\"40%\">\n",
    "<img src=\"https://github.com/marcoteran/machinelearning/raw/master/notebooks/01_machinelearnig/figures/lowgamma.png\" width=\"40%\">\n",
    "\n",
    "La elección adecuada de $C$ y $\\gamma$ es fundamental para el rendimiento de la SVM. Se aconseja utilizar `GridSearchCV` con $C$ y $\\gamma$ espaciados exponencialmente para elegir buenos valores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el siguiente ejemplo probamos con un valor de $\\gamma$ pequeño $(0.007)$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargamos el clasificador\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenamos el clasificador\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora visualizamos los datos de ambos y la superficie de decisión:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reportamos el error de entrenamiento y prueba:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Error en entrenamiento\n",
    "# Error en prueba\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usamos un $\\gamma$ más grande $(10000)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora reportamos el error de entrenamiento y prueba:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Error en entrenamiento\n",
    "# Error en prueba\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora escogemos un valor de $\\gamma$ intermedio $(0.7)$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Error en entrenamiento\n",
    "# Error en prueba\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Probamos sobre el conjunto de datos IRIS $(\\gamma=0.7)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalmente reportamos el error en entrenamiento y prueba:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Error en entrenamiento\n",
    "# Error en prueba\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estimando de una forma más robusta los hiperparámetros del modelo\n",
    "\n",
    "Hasta el momento nos hemos concentrado en evaluar nuestros modelos en una partición de prueba. Sin embargo, es común introducir sobreajuste a través de la modificación manual de los hiperparámetros de un modelo conforme vamos reportando el error de generalización sobre el conjunto de prueba.\n",
    "\n",
    "<img src=\"https://github.com/marcoteran/machinelearning/raw/master/notebooks/01_machinelearnig/figures/train_val.svg\" width=\"70%\">\n",
    "\n",
    "En la anterior imagen, introducimos una nueva partición, conocida como partición de \"**validación**\". Esta partición es resultado de tomar la partición de entrenamiento y volver a dividirla (en entrenamiento y validación) de tal forma que cualquier configuración de parámetros que se use para entrenar un modelo, pueda ser reportada en **validación**. Una vez estemos seguros que tenemos el modelo con el mejor desempeño en **validación**, volvemos a unir ambas particiones, entrenamos un modelo sobre la partición original de entrenamiento y reportamos **una sola vez** en el conjunto de prueba."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validación cruzada de  k pliegues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A pesar de que se introdujo una nueva partición para validar los parámetros de un modelo, se sigue usando una partición reducida para entrenar el conjunto de datos. La validación cruzada nos permite usar una mayor parte de los datos para construír el modelo y generar un estimador más robusto y con mayor capacidad de generalización. En validación cruzada, los datos son particionados varias veces en entrenamiento y validación de forma repetida. Finalmente el desempeño del clasificador es agregado sobre las diferentes particiones de validación para obtener un estimador más robusto.\n",
    "\n",
    "La validación cruzada se hace comúnmente de la siguiente manera:\n",
    "* Se divide el conjunto de entrenamiento en k-pliegues o particiones (usualmente 3, 5 o 10).\n",
    "* Estas particiones deben ser del mismo tamaño\n",
    "* En cada iteración uno de los pliegues es usado como la partición de validación, mientras el resto es usado como la partición de entrenamiento.\n",
    "* Se reporta y guarda el desempeño sobre esa partición de validación\n",
    "\n",
    "<img src=\"https://github.com/marcoteran/machinelearning/raw/master/notebooks/01_machinelearnig/figures/cv2.svg\" width=\"70%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a usar el conjunto de datos IRIS y construímos cada uno de los pliegues:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargamos los datos iris\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos el clasificador LinearSVC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Número de pliegues k=5 (mostrar tamaño de cada pliegue)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primero hacemos un reordenamiento aleatorio de los datos utilizando la función `shuffle`. De tal forma que las clases estén distribuídas a lo largo de los $k$-pliegues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para cada pliegue vamos a construir una máscara sobre los datos, que indicará mi partición de entrenamiento y de validación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostrar la distribución de equiquetas por pliegue\n",
    "scores = []\n",
    "masks = []\n",
    "\n",
    "\n",
    "for fold in range(k):\n",
    "    val_mask = np.zeros(n_samples, dtype=bool)\n",
    "    val_mask[fold * fold_size : (fold + 1) * fold_size] = True\n",
    "    masks.append(val_mask)\n",
    "    X_val, y_val = X[val_mask], y[val_mask]\n",
    "    print('Distribución de etiquetas en el pliegue {}: {}'\n",
    "          .format(fold, np.bincount(y_val)))\n",
    "    \n",
    "    X_train, y_train = X[~val_mask], y[~val_mask]\n",
    "    classifier.fit(X_train, y_train)\n",
    "    scores.append(classifier.score(X_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación tenemos el accuracy para cada pliegue de **validación** y su respectivo promedio:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostramos la accuracy por cada pliegue\n",
    "# Mostramos promedio sobre los 5 pliegues\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos tambien observar la porción de los datos usados para cada pliegue. En negro encontramos aquel porcentaje usado para validación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dibujas las mascaras\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validación cruzada usando Scikit-Learn\n",
    "\n",
    "Scikit-Learn provee una implementación muy eficiente para realizar **validación cruzada** usando `sklearn.model_selection` [(ver más)](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html). `sklearn.model_selection.cross_val_score` recibe un estimador y un conjunto de datos, luego \n",
    "hace el particionamiento y entrena un modelo sobre cada partición de validación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score, KFold, StratifiedKFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El parámetro `cv` en `cross_val_score` controla el número de pliegues a usar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carga de datos iris\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validación cruzada para k=5\n",
    "scores = cross_val_score(classifier, X, y, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostramos la accuracy por cada pliegue\n",
    "# Mostramos promedio sobre los 5 pliegues\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`cross_val_score` realiza por defecto una partición estratificada usando `sklearn.model_selection.StratifiedKFold`. Esta estrategia consiste en hacer un particionamiento de tal forma que cada partición tenga la misma distribución de etiquetas $y$. En caso que no se quiera hacer una partición estratificada, se puede usar `sklearn.model_selection.KFold`.\n",
    "\n",
    "`sklearn.model_selection.StratifiedKFold` genera de forma automática la partición estratificada, sin necesidad de hacer una permutación de los datos como lo hicimos anteriormente. A continuación revisamos los índices que genera `StratifiedKFold`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Realizar la estratificación y mostrar:\n",
    "# Tamaño entrenamiento:\n",
    "# Tamaño validación:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usando una función definida previamente, vamos a validar la distribución de las etiquetas por clase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utilizar plot_labels con StratifiedKFold\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por otro lado, usando `KFold` podemos obtener un particionamiento de tantos pliegues como se especifiquen. Sin embargo, se corre el riesgo de no generar particiones balanceadas, por lo tanto lo estimadores no van a tener el desempeño esperado. Por ejemplo en el **Pliegue 0** solo hay datos de la clase $0$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utilizar plot_labels con KFold\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVM usando RBF comúnmente requiere el ajuste de dos parámetros:\n",
    "* `gamma`\n",
    "* `C`\n",
    "\n",
    "Ambos parámetros pueden ser explorados usando un retículo (grid) de parámetros y evaluando su desempeño usando validación cruzada de $k$ pliegues. A continuación, creamos una partición entrenamiento y prueba sobre el conjunto de datos IRIS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# especificar estratificación"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definimos los siguientes valores para $C=2i$ y $\\gamma=i^2$, para $i=\\{-5,7\\}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Valores de $C$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Valores de $\\textit{gamma}$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`GridSearchCV` recibe dos elementos fundamentales:\n",
    "* `estimator`: Modelo de Scikit-Learn. Puede ser `SVC(kernel='rbf')`.\n",
    "* `param_grid`: Diccionario que contiene los parámetros que se van a explorar usando validación cruzada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los valores promedio de accuracy para cada combinación de hiperparámetros se pueden extraer usando `GridSearchCV.cv_results_`. Convertimos ese diccionario a un DataFrame de pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación, observamos que el número de filas de ese DataFrame corresponde al número de configuraciones de hiperparámetros que se están explorando:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usando la columna `mean_test_score`, extraemos los accuracy promedio de la siguiente forma:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación, presentamos una forma de visualizar esta exploración sobre la malla de hiperparámetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.subplots_adjust(left=.2, right=0.95, bottom=0.15, top=0.95)\n",
    "plt.imshow(scores, interpolation='nearest', cmap=plt.cm.hot,\n",
    "           norm=MidpointNormalize(vmin=0.2, midpoint=0.92, vmax=1.))\n",
    "plt.xlabel('gamma')\n",
    "plt.ylabel('C')\n",
    "plt.colorbar()\n",
    "plt.xticks(np.arange(len(param_grid['gamma'])), param_grid['gamma'], rotation=45)\n",
    "plt.yticks(np.arange(len(param_grid['C'])), param_grid['C'])\n",
    "plt.title('Accuracy en validación')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encontramos que existen tres modelos con el mejor desempeño usando validación cruzada:\n",
    "* $C=2$ y $\\gamma=0.5$\n",
    "* $C=8$ y $\\gamma=0.125$\n",
    "* $C=4$ y $\\gamma=0.5$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para validar esta información, `GridSearchCV` nos ofrece una serie de métodos que nos permite consultar:\n",
    "* La lista de resultados por elemento en la malla de parámetros (`cv_results_`)\n",
    "* La configuración con el mejor desempeño (`best_params_`)\n",
    "* El accuracy promediado sobre todos los pliegues de la mejor configuración (`best_score_`)\n",
    "\n",
    "Para encontrar las mejores configuraciones, ordenamos la tabla de resultados de la siguiente manera:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta información también se puede consultar usando `.best_params_` y `.best_score_`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez se haya entrenado el modelo usando validación cruzada, `GridSearchCV` escoge automáticamente la mejor configuración y vuelve a entrenar un modelo sobre todo el conjunto de datos de entrenamiento. Por lo tanto se pueden hacer llamados a funciones como `predict()` y `score()`.\n",
    "\n",
    "Para reportar sobre el conjunto de prueba basta con:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Taller\n",
    "\n",
    "Siguiendo con el conjunto de datos **Wine**.\n",
    "\n",
    "# Conjunto de datos:\n",
    "\n",
    "* Cargue el conjunto de datos **Wine**.\n",
    "\n",
    "## Explorando `Proline` contra `Flavonoids`\n",
    "* Construya un conjunto de datos usando las características `Proline` contra `Flavonoids`.\n",
    "* Escale el conjunto de datos de tal forma que tenga media cero y varianza uno:\n",
    "\n",
    "```python\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "sc_x = StandardScaler()\n",
    "sc_x.fit(X)\n",
    "X_scaled = sc_x.transform(X)\n",
    "```\n",
    "\n",
    "* Genere una partición estratificada 70-30 sobre el conjunto de datos.\n",
    "* Use la siguiente retícula de parámetros:\n",
    "\n",
    "```python\n",
    "grid = [i for i in range(-5, 7, 1)]\n",
    "param_grid = {'C': [2**i for i in grid], 'gamma': [2**i for i in grid]}\n",
    "```\n",
    "*  Explore el parámetro óptimo $\\gamma$ y $C$ para un SVM con kernel gaussiano. Hágalo en 5 pliegues.\n",
    "* Visualice el desempeño del clasificador sobre la retícula de parámetros como un mapa de calor. Use el código que se manejó en la sesión.\n",
    "* ¿Cual es la mejor configuración?\n",
    "* ¿Qué desempeño tiene la mejor configuración?\n",
    "* Grafique la superficie de decisión contra los ejemplos de prueba.\n",
    "* Reporte accuracy, precision, recall y matriz de confusión en el conjunto de prueba\n",
    "\n",
    "## Usando todas las características\n",
    "* Escale **todo** el conjunto de datos de tal forma que tenga media cero y varianza uno. Use el código que se proporcionó arriba.\n",
    "* Genere una partición estratificada 70-30 sobre el conjunto de datos.\n",
    "* Use la siguiente retícula de parámetros:\n",
    "\n",
    "```python\n",
    "grid = [i for i in range(-7, 8, 1)]\n",
    "param_grid = {'C': [2**i for i in grid], 'gamma': [2**i for i in grid]}\n",
    "```\n",
    "*  Explore el parámetro óptimo $\\gamma$ y $C$ para un SVM con kernel gaussiano. Hágalo en 5 pliegues.\n",
    "* Visualice el desempeño del clasificador sobre la retícula de parámetros como un mapa de calor. Use el código que se manejó en la sesión.\n",
    "* ¿Cual es la mejor configuración?\n",
    "* ¿Qué desempeño tiene la mejor configuración?\n",
    "* Reporte accuracy, precision, recall y matriz de confusión en el conjunto de prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
